{"cells":[{"cell_type":"code","execution_count":1,"id":"198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3","metadata":{"id":"198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3","executionInfo":{"status":"ok","timestamp":1702255419579,"user_tz":300,"elapsed":10222,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["import os\n","import random\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import torchvision\n","\n","from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n","from torchvision import transforms\n","from PIL import Image"]},{"cell_type":"code","source":["from torchvision import models\n","backbone = models.resnet18(weights='IMAGENET1K_V1')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdTqQl3sTEgf","executionInfo":{"status":"ok","timestamp":1702255420667,"user_tz":300,"elapsed":1089,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"f6bbd40c-1e1c-4a93-f996-7218aa7663fb"},"id":"SdTqQl3sTEgf","execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 81.9MB/s]\n"]}]},{"cell_type":"code","source":["backbone"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpRXrXsNTQXn","executionInfo":{"status":"ok","timestamp":1702255420839,"user_tz":300,"elapsed":175,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"65f45002-e22d-45c7-fd6a-79b9312d1554"},"id":"cpRXrXsNTQXn","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/NNDL_Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-yM4gnrFJ6l","executionInfo":{"status":"ok","timestamp":1702255438230,"user_tz":300,"elapsed":17394,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"2033a123-0d57-4dcd-8d80-b1df27e283d4"},"id":"x-yM4gnrFJ6l","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/NNDL_Project\n"]}]},{"cell_type":"code","source":["%%capture\n","! unzip -o train_shuffle.zip"],"metadata":{"id":"761mGvPYkeIV"},"id":"761mGvPYkeIV","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","! unzip -o test_shuffle.zip"],"metadata":{"id":"7L3niCJakf41"},"id":"7L3niCJakf41","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":13,"id":"c370d643-46fd-4d03-bb17-a875e79d5e2c","metadata":{"id":"c370d643-46fd-4d03-bb17-a875e79d5e2c","executionInfo":{"status":"ok","timestamp":1702255726434,"user_tz":300,"elapsed":154,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["# Create Dataset class for multilabel classification\n","class MultiClassImageDataset(Dataset):\n","    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n","        self.ann_df = ann_df\n","        self.super_map_df = super_map_df\n","        self.sub_map_df = sub_map_df\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.ann_df)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.ann_df['image'][idx]\n","        img_path = os.path.join(self.img_dir, img_name)\n","        image = Image.open(img_path).convert('RGB')\n","\n","        super_idx = self.ann_df['superclass_index'][idx]\n","        super_label = self.super_map_df['class'][super_idx]\n","\n","        sub_idx = self.ann_df['subclass_index'][idx]\n","        sub_label = self.sub_map_df['class'][sub_idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, super_idx, super_label, sub_idx, sub_label\n","\n","class MultiClassImageTestDataset(Dataset):\n","    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n","        self.super_map_df = super_map_df\n","        self.sub_map_df = sub_map_df\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self): # Count files in img_dir\n","        return len([fname for fname in os.listdir(self.img_dir)])\n","\n","    def __getitem__(self, idx):\n","        img_name = str(idx) + '.jpg'\n","        img_path = os.path.join(self.img_dir, img_name)\n","        image = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, img_name"]},{"cell_type":"code","execution_count":23,"id":"e7398553-8842-4ad8-b348-767921a22482","metadata":{"id":"e7398553-8842-4ad8-b348-767921a22482","executionInfo":{"status":"ok","timestamp":1702256192721,"user_tz":300,"elapsed":157,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["train_ann_df = pd.read_csv('train_data.csv')\n","super_map_df = pd.read_csv('superclass_mapping.csv')\n","sub_map_df = pd.read_csv('subclass_mapping.csv')\n","\n","train_img_dir = 'train_shuffle'\n","test_img_dir = 'test_shuffle'\n","\n","image_preprocessing = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0), std=(1)),\n","])\n","\n","# Create train and val split\n","train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n","train_dataset, val_dataset = random_split(train_dataset, [0.9, 0.1])\n","\n","# Create test dataset\n","test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=image_preprocessing)\n","\n","# Create dataloaders\n","batch_size = 64\n","train_loader = DataLoader(train_dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True, drop_last = True)\n","\n","val_loader = DataLoader(val_dataset,\n","                        batch_size=batch_size,\n","                        shuffle=True, drop_last = True)\n","\n","test_loader = DataLoader(test_dataset,\n","                         batch_size=1,\n","                         shuffle=False)"]},{"cell_type":"code","execution_count":62,"id":"bf33a131-0c66-40dc-b8d4-ba5d0f840840","metadata":{"id":"bf33a131-0c66-40dc-b8d4-ba5d0f840840","executionInfo":{"status":"ok","timestamp":1702257707962,"user_tz":300,"elapsed":144,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["# Simple CNN\n","class CNN(nn.Module):\n","    def __init__(self, backbone, finetune=False):\n","        super().__init__()\n","\n","        self.backbone = backbone\n","        num_ftrs = self.backbone.fc.in_features\n","        print('num_ftrs: ', num_ftrs)\n","        self.backbone.fc = torch.nn.Identity()\n","        print(self.backbone)\n","\n","        if not finetune:\n","          for param in self.backbone.parameters():\n","            param.requires_grad = False\n","        else:\n","          for i, layer in enumerate(self.backbone.children()):\n","            if i < 6: #just train last of the main convolutional layers\n","              for param in layer.parameters():\n","                param.requires_grad = False\n","            else:\n","              for param in layer.parameters():\n","                param.requires_grad = True\n","\n","\n","        # Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n","        self.fca= nn.Linear(num_ftrs, 4)\n","        self.fcb= nn.Linear(num_ftrs, 88)\n","\n","\n","    def forward(self, x):\n","        x_new = self.backbone(x)\n","        super_out = self.fca(x_new)\n","        sub_out = self.fcb(x_new)\n","        return super_out, sub_out\n","\n","class Trainer():\n","    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n","        self.model = model\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.test_loader = test_loader\n","        self.device = device\n","\n","    def train_epoch(self):\n","        running_loss = 0.0\n","        device = self.device\n","        for i, data in enumerate(self.train_loader):\n","            inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n","\n","            self.optimizer.zero_grad()\n","            super_outputs, sub_outputs = self.model(inputs)\n","            loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f'Training loss: {running_loss/i:.3f}')\n","\n","    def validate_epoch(self):\n","        super_correct = 0\n","        sub_correct = 0\n","        total = 0\n","        running_loss = 0.0\n","        device = self.device\n","        with torch.no_grad():\n","            for i, data in enumerate(self.val_loader):\n","                inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n","\n","                super_outputs, sub_outputs = self.model(inputs)\n","                loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n","                _, super_predicted = torch.max(super_outputs.data, 1)\n","                _, sub_predicted = torch.max(sub_outputs.data, 1)\n","\n","                total += super_labels.size(0)\n","                super_correct += (super_predicted == super_labels).sum().item()\n","                sub_correct += (sub_predicted == sub_labels).sum().item()\n","                running_loss += loss.item()\n","\n","        print(f'Validation loss: {running_loss/i:.3f}')\n","        print(f'Validation superclass acc: {100 * super_correct / total:.2f} %')\n","        print(f'Validation subclass acc: {100 * sub_correct / total:.2f} %')\n","\n","    def test(self, save_to_csv=False, return_predictions=False):\n","        if not self.test_loader:\n","            raise NotImplementedError('test_loader not specified')\n","\n","        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n","        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n","        with torch.no_grad():\n","            for i, data in enumerate(self.test_loader):\n","                inputs, img_name = data[0].to(device), data[1]\n","\n","                super_outputs, sub_outputs = self.model(inputs)\n","                _, super_predicted = torch.max(super_outputs.data, 1)\n","                _, sub_predicted = torch.max(sub_outputs.data, 1)\n","\n","                test_predictions['image'].append(img_name[0])\n","                test_predictions['superclass_index'].append(super_predicted.item())\n","                test_predictions['subclass_index'].append(sub_predicted.item())\n","\n","        test_predictions = pd.DataFrame(data=test_predictions)\n","\n","        if save_to_csv:\n","            test_predictions.to_csv('transfer_learning_superandsub_test_predictions.csv', index=False)\n","\n","        if return_predictions:\n","            return test_predictions"]},{"cell_type":"code","source":["def fine_tune(backbone):\n","  for i, layer in enumerate(backbone.children()):\n","    if i < 6: #just train last of the main convolutional layers\n","      for param in layer.parameters():\n","        param.requires_grad = False\n","    else:\n","      for param in layer.parameters():\n","        param.requires_grad = True\n","  return"],"metadata":{"id":"vTqAm1vX9fgt","executionInfo":{"status":"ok","timestamp":1702257708841,"user_tz":300,"elapsed":3,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"id":"vTqAm1vX9fgt","execution_count":63,"outputs":[]},{"cell_type":"code","execution_count":64,"id":"ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1","metadata":{"id":"ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1","executionInfo":{"status":"ok","timestamp":1702257709635,"user_tz":300,"elapsed":178,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd346bfd-1e38-4aeb-f363-c8a4bc5c3010"},"outputs":[{"output_type":"stream","name":"stdout","text":["num_ftrs:  512\n","ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Identity()\n",")\n","num_ftrs:  512\n"]}],"source":["# Init model and trainer\n","device = 'cuda'\n","backbone = models.resnet18(weights='IMAGENET1K_V1')\n","finetune = False\n","model = CNN(backbone, finetune=finetune).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"]},{"cell_type":"code","execution_count":65,"id":"7941c289-d9b1-4714-b788-898b3b889f58","metadata":{"id":"7941c289-d9b1-4714-b788-898b3b889f58","outputId":"047247e9-50d9-4bc2-b41b-18d73d29cb94","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702257983220,"user_tz":300,"elapsed":271585,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable parameters:  47196\n","Total parameters:  11223708\n","----------------------\n","\n","Epoch 1\n","Training loss: 4.942\n","Validation loss: 4.634\n","Validation superclass acc: 71.88 %\n","Validation subclass acc: 22.05 %\n","\n","Epoch 2\n","Training loss: 3.728\n","Validation loss: 4.246\n","Validation superclass acc: 75.69 %\n","Validation subclass acc: 24.13 %\n","\n","Epoch 3\n","Training loss: 3.289\n","Validation loss: 4.107\n","Validation superclass acc: 76.22 %\n","Validation subclass acc: 26.91 %\n","\n","Epoch 4\n","Training loss: 3.039\n","Validation loss: 4.056\n","Validation superclass acc: 76.56 %\n","Validation subclass acc: 26.91 %\n","\n","Epoch 5\n","Training loss: 2.894\n","Validation loss: 4.034\n","Validation superclass acc: 73.61 %\n","Validation subclass acc: 28.82 %\n","\n","Epoch 6\n","Training loss: 2.745\n","Validation loss: 3.957\n","Validation superclass acc: 76.22 %\n","Validation subclass acc: 29.17 %\n","\n","Epoch 7\n","Training loss: 2.631\n","Validation loss: 3.888\n","Validation superclass acc: 78.30 %\n","Validation subclass acc: 32.81 %\n","\n","Epoch 8\n","Training loss: 2.544\n","Validation loss: 3.920\n","Validation superclass acc: 77.08 %\n","Validation subclass acc: 30.73 %\n","\n","Epoch 9\n","Training loss: 2.466\n","Validation loss: 3.842\n","Validation superclass acc: 80.56 %\n","Validation subclass acc: 28.65 %\n","\n","Epoch 10\n","Training loss: 2.431\n","Validation loss: 3.944\n","Validation superclass acc: 78.47 %\n","Validation subclass acc: 29.69 %\n","\n","Epoch 11\n","Training loss: 2.369\n","Validation loss: 3.921\n","Validation superclass acc: 77.78 %\n","Validation subclass acc: 30.38 %\n","\n","\n","Trainable parameters:  10540636\n","Total parameters:  11223708\n","----------------------\n","\n","Epoch 12\n","Training loss: 2.759\n","Validation loss: 2.521\n","Validation superclass acc: 91.15 %\n","Validation subclass acc: 46.70 %\n","\n","Epoch 13\n","Training loss: 1.482\n","Validation loss: 2.192\n","Validation superclass acc: 92.19 %\n","Validation subclass acc: 48.61 %\n","\n","Epoch 14\n","Training loss: 1.007\n","Validation loss: 2.158\n","Validation superclass acc: 94.10 %\n","Validation subclass acc: 52.60 %\n","\n","Epoch 15\n","Training loss: 0.745\n","Validation loss: 2.264\n","Validation superclass acc: 92.88 %\n","Validation subclass acc: 55.56 %\n","\n","Epoch 16\n","Training loss: 0.633\n","Validation loss: 2.523\n","Validation superclass acc: 90.45 %\n","Validation subclass acc: 55.21 %\n","\n","Epoch 17\n","Training loss: 0.475\n","Validation loss: 2.229\n","Validation superclass acc: 93.58 %\n","Validation subclass acc: 57.99 %\n","\n","Epoch 18\n","Training loss: 0.362\n","Validation loss: 2.762\n","Validation superclass acc: 92.53 %\n","Validation subclass acc: 57.12 %\n","\n","Epoch 19\n","Training loss: 0.280\n","Validation loss: 2.650\n","Validation superclass acc: 94.44 %\n","Validation subclass acc: 58.51 %\n","\n","Epoch 20\n","Training loss: 0.197\n","Validation loss: 2.780\n","Validation superclass acc: 94.62 %\n","Validation subclass acc: 56.77 %\n","\n","Epoch 21\n","Training loss: 0.258\n","Validation loss: 3.268\n","Validation superclass acc: 92.88 %\n","Validation subclass acc: 53.65 %\n","\n","Epoch 22\n","Training loss: 0.259\n","Validation loss: 2.977\n","Validation superclass acc: 93.40 %\n","Validation subclass acc: 57.81 %\n","\n","Epoch 23\n","Training loss: 0.239\n","Validation loss: 2.945\n","Validation superclass acc: 93.75 %\n","Validation subclass acc: 57.81 %\n","\n","Epoch 24\n","Training loss: 0.200\n","Validation loss: 2.885\n","Validation superclass acc: 93.58 %\n","Validation subclass acc: 58.33 %\n","\n","Epoch 25\n","Training loss: 0.181\n","Validation loss: 3.136\n","Validation superclass acc: 90.80 %\n","Validation subclass acc: 58.51 %\n","\n","Finished Training\n"]}],"source":["# Training loop\n","print('Trainable parameters: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n","print('Total parameters: ', sum(p.numel() for p in model.parameters()))\n","print('----------------------')\n","print('')\n","for epoch in range(25):\n","    print(f'Epoch {epoch+1}')\n","    trainer.train_epoch()\n","    trainer.validate_epoch()\n","    print('')\n","    if epoch == 10:\n","      fine_tune(trainer.model.backbone)\n","      print('')\n","      print('Trainable parameters: ', sum(p.numel() for p in trainer.model.parameters() if p.requires_grad))\n","      print('Total parameters: ', sum(p.numel() for p in trainer.model.parameters()))\n","      print('----------------------')\n","      print('')\n","      trainer = Trainer(trainer.model, trainer.criterion, trainer.optimizer, trainer.train_loader, trainer.val_loader, trainer.test_loader)\n","\n","\n","print('Finished Training')"]},{"cell_type":"code","execution_count":66,"id":"16d17e37-1a08-4ae1-8517-a16ff4769622","metadata":{"id":"16d17e37-1a08-4ae1-8517-a16ff4769622","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1702258121713,"user_tz":300,"elapsed":106302,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"9eff5cd1-9912-44f8-d051-c1041a05b0f0"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nThis simple baseline scores the following test accuracy\\n\\nSuperclass Accuracy\\nOverall: 43.83 %\\nSeen: 61.11 %\\nUnseen: 0.00 %\\n\\nSubclass Accuracy\\nOverall: 2.03 %\\nSeen: 9.56 %\\nUnseen: 0.00 %\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":66}],"source":["trainer.model.eval()\n","trainer.test(save_to_csv=False, return_predictions=True)\n","\n","'''\n","This simple baseline scores the following test accuracy\n","\n","Superclass Accuracy\n","Overall: 43.83 %\n","Seen: 61.11 %\n","Unseen: 0.00 %\n","\n","Subclass Accuracy\n","Overall: 2.03 %\n","Seen: 9.56 %\n","Unseen: 0.00 %\n","'''"]},{"cell_type":"code","execution_count":null,"id":"6ab70fb9-6e14-49f1-b9bb-5f3da6807399","metadata":{"id":"6ab70fb9-6e14-49f1-b9bb-5f3da6807399","executionInfo":{"status":"aborted","timestamp":1702255691480,"user_tz":300,"elapsed":4,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}