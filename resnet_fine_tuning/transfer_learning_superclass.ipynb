{"cells":[{"cell_type":"code","execution_count":1,"id":"198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3","metadata":{"id":"198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3","executionInfo":{"status":"ok","timestamp":1702258882292,"user_tz":300,"elapsed":9725,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["import os\n","import random\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import torchvision\n","\n","from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n","from torchvision import transforms\n","from PIL import Image"]},{"cell_type":"code","source":["from torchvision import models\n","backbone = models.resnet18(weights='IMAGENET1K_V1')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdTqQl3sTEgf","executionInfo":{"status":"ok","timestamp":1702258883658,"user_tz":300,"elapsed":1369,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"56f18a0f-eb86-4987-9fca-6c3921e5218b"},"id":"SdTqQl3sTEgf","execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 57.6MB/s]\n"]}]},{"cell_type":"code","source":["backbone"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpRXrXsNTQXn","executionInfo":{"status":"ok","timestamp":1702258883800,"user_tz":300,"elapsed":5,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"87714d43-ba21-4f33-c560-5b64abf59f4d"},"id":"cpRXrXsNTQXn","execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/NNDL_Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-yM4gnrFJ6l","executionInfo":{"status":"ok","timestamp":1702258898147,"user_tz":300,"elapsed":14350,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"12638ffd-449a-434a-fd97-3016d0421cfc"},"id":"x-yM4gnrFJ6l","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/NNDL_Project\n"]}]},{"cell_type":"code","source":["%%capture\n","! unzip -o train_shuffle.zip"],"metadata":{"id":"2MMkMZQD3Cuh","executionInfo":{"status":"ok","timestamp":1702258989709,"user_tz":300,"elapsed":91566,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"id":"2MMkMZQD3Cuh","execution_count":5,"outputs":[]},{"cell_type":"code","source":["%%capture\n","! unzip -o test_shuffle.zip"],"metadata":{"id":"neQE1YRn3D7W","executionInfo":{"status":"ok","timestamp":1702259157275,"user_tz":300,"elapsed":167569,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"id":"neQE1YRn3D7W","execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"id":"c370d643-46fd-4d03-bb17-a875e79d5e2c","metadata":{"id":"c370d643-46fd-4d03-bb17-a875e79d5e2c","executionInfo":{"status":"ok","timestamp":1702259157276,"user_tz":300,"elapsed":8,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["# Create Dataset class for multilabel classification\n","class MultiClassImageDataset(Dataset):\n","    def __init__(self, ann_df, super_map_df, img_dir, transform=None):\n","        self.ann_df = ann_df\n","        self.super_map_df = super_map_df\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.ann_df)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.ann_df['image'][idx]\n","        img_path = os.path.join(self.img_dir, img_name)\n","        image = Image.open(img_path).convert('RGB')\n","\n","        super_idx = self.ann_df['superclass_index'][idx]\n","        super_label = self.super_map_df['class'][super_idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, super_idx, super_label\n","\n","class MultiClassImageTestDataset(Dataset):\n","    def __init__(self, super_map_df, img_dir, transform=None):\n","        self.super_map_df = super_map_df\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self): # Count files in img_dir\n","        return len([fname for fname in os.listdir(self.img_dir)])\n","\n","    def __getitem__(self, idx):\n","        img_name = str(idx) + '.jpg'\n","        img_path = os.path.join(self.img_dir, img_name)\n","        image = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, img_name"]},{"cell_type":"code","execution_count":8,"id":"e7398553-8842-4ad8-b348-767921a22482","metadata":{"id":"e7398553-8842-4ad8-b348-767921a22482","executionInfo":{"status":"ok","timestamp":1702259157992,"user_tz":300,"elapsed":722,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["train_ann_df = pd.read_csv('train_data.csv')\n","super_map_df = pd.read_csv('superclass_mapping.csv')\n","sub_map_df = pd.read_csv('subclass_mapping.csv')\n","\n","train_img_dir = 'train_shuffle'\n","test_img_dir = 'test_shuffle'\n","\n","image_preprocessing = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0), std=(1)),\n","])\n","\n","# Create train and val split\n","train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, train_img_dir, transform=image_preprocessing)\n","train_dataset, val_dataset = random_split(train_dataset, [0.9, 0.1])\n","\n","# Create test dataset\n","test_dataset = MultiClassImageTestDataset(super_map_df, test_img_dir, transform=image_preprocessing)\n","\n","# Create dataloaders\n","batch_size = 64\n","train_loader = DataLoader(train_dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True, drop_last = True)\n","\n","val_loader = DataLoader(val_dataset,\n","                        batch_size=batch_size,\n","                        shuffle=True, drop_last = True)\n","\n","test_loader = DataLoader(test_dataset,\n","                         batch_size=1,\n","                         shuffle=False)"]},{"cell_type":"code","execution_count":17,"id":"bf33a131-0c66-40dc-b8d4-ba5d0f840840","metadata":{"id":"bf33a131-0c66-40dc-b8d4-ba5d0f840840","executionInfo":{"status":"ok","timestamp":1702259254191,"user_tz":300,"elapsed":126,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["# Simple CNN\n","class CNN(nn.Module):\n","    def __init__(self, backbone, finetune=False):\n","        super().__init__()\n","\n","        self.backbone = backbone\n","\n","        if not finetune:\n","          for param in self.backbone.parameters():\n","            param.requires_grad = False\n","        else:\n","          for i, layer in enumerate(self.backbone.children()):\n","            if i < 6: #just train last of the main convolutional layers\n","              for param in layer.parameters():\n","                param.requires_grad = False\n","            else:\n","              for param in layer.parameters():\n","                param.requires_grad = True\n","\n","        num_ftrs = self.backbone.fc.in_features\n","        self.backbone.fc = nn.Linear(num_ftrs, 4)\n","\n","    def forward(self, x):\n","        super_out = self.backbone(x)\n","        return super_out\n","\n","class Trainer():\n","    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n","        self.model = model\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.test_loader = test_loader\n","        self.device = device\n","\n","    def train_epoch(self):\n","        running_loss = 0.0\n","        device = self.device\n","        for i, data in enumerate(self.train_loader):\n","            inputs, super_labels = data[0].to(device), data[1].to(device)\n","\n","            self.optimizer.zero_grad()\n","            super_outputs = self.model(inputs)\n","            loss = self.criterion(super_outputs, super_labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f'Training loss: {running_loss/i:.3f}')\n","\n","    def validate_epoch(self):\n","        super_correct = 0\n","        total = 0\n","        running_loss = 0.0\n","        device = self.device\n","        with torch.no_grad():\n","            for i, data in enumerate(self.val_loader):\n","                inputs, super_labels = data[0].to(device), data[1].to(device)\n","\n","                super_outputs = self.model(inputs)\n","                loss = self.criterion(super_outputs, super_labels)\n","                _, super_predicted = torch.max(super_outputs.data, 1)\n","\n","                total += super_labels.size(0)\n","                super_correct += (super_predicted == super_labels).sum().item()\n","                running_loss += loss.item()\n","\n","        print(f'Validation loss: {running_loss/i:.3f}')\n","        print(f'Validation superclass acc: {100 * super_correct / total:.2f} %')\n","\n","    def test(self, save_to_csv=False, return_predictions=False):\n","        if not self.test_loader:\n","            raise NotImplementedError('test_loader not specified')\n","\n","        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n","        test_predictions = {'image': [], 'superclass_index': []}\n","        with torch.no_grad():\n","            for i, data in enumerate(self.test_loader):\n","                inputs, img_name = data[0].to(device), data[1]\n","\n","                super_outputs = self.model(inputs)\n","                _, super_predicted = torch.max(super_outputs.data, 1)\n","\n","                test_predictions['image'].append(img_name[0])\n","                test_predictions['superclass_index'].append(super_predicted.item())\n","\n","        test_predictions = pd.DataFrame(data=test_predictions)\n","\n","        if save_to_csv:\n","            test_predictions.to_csv('transfer_learning_superclass_test_predictions.csv', index=False)\n","\n","        if return_predictions:\n","            return test_predictions"]},{"cell_type":"code","source":["def fine_tune(backbone):\n","  for i, layer in enumerate(backbone.children()):\n","    if i < 6: #just train last of the main convolutional layers\n","      for param in layer.parameters():\n","        param.requires_grad = False\n","    else:\n","      for param in layer.parameters():\n","        param.requires_grad = True\n","  return"],"metadata":{"id":"vTqAm1vX9fgt","executionInfo":{"status":"ok","timestamp":1702259254308,"user_tz":300,"elapsed":118,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"id":"vTqAm1vX9fgt","execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":19,"id":"ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1","metadata":{"id":"ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1","executionInfo":{"status":"ok","timestamp":1702259254662,"user_tz":300,"elapsed":355,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["# Init model and trainer\n","device = 'cuda'\n","backbone = models.resnet18(weights='IMAGENET1K_V1')\n","finetune = False\n","model = CNN(backbone, finetune=finetune).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"]},{"cell_type":"code","execution_count":20,"id":"7941c289-d9b1-4714-b788-898b3b889f58","metadata":{"id":"7941c289-d9b1-4714-b788-898b3b889f58","outputId":"8d890f6c-5e49-4434-933b-6b9862cb4f8f","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1702259402845,"user_tz":300,"elapsed":148184,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable parameters:  2052\n","Total parameters:  11178564\n","----------------------\n","\n","Epoch 1\n","Training loss: 0.881\n","Validation loss: 0.790\n","Validation superclass acc: 69.97 %\n","\n","Epoch 2\n","Training loss: 0.667\n","Validation loss: 0.788\n","Validation superclass acc: 70.49 %\n","\n","Epoch 3\n","Training loss: 0.608\n","Validation loss: 0.738\n","Validation superclass acc: 71.53 %\n","\n","Epoch 4\n","Training loss: 0.590\n","Validation loss: 0.725\n","Validation superclass acc: 72.74 %\n","\n","Epoch 5\n","Training loss: 0.583\n","Validation loss: 0.668\n","Validation superclass acc: 75.35 %\n","\n","Epoch 6\n","Training loss: 0.580\n","Validation loss: 0.708\n","Validation superclass acc: 72.57 %\n","\n","Epoch 7\n","Training loss: 0.560\n","Validation loss: 0.698\n","Validation superclass acc: 74.83 %\n","\n","Epoch 8\n","Training loss: 0.556\n","Validation loss: 0.699\n","Validation superclass acc: 72.22 %\n","\n","Epoch 9\n","Training loss: 0.561\n","Validation loss: 0.662\n","Validation superclass acc: 73.78 %\n","\n","Epoch 10\n","Training loss: 0.552\n","Validation loss: 0.676\n","Validation superclass acc: 76.39 %\n","\n","Epoch 11\n","Training loss: 0.550\n","Validation loss: 0.674\n","Validation superclass acc: 75.35 %\n","\n","\n","Trainable parameters:  10495492\n","Total parameters:  11178564\n","----------------------\n","\n","Epoch 12\n","Training loss: 0.383\n","Validation loss: 0.314\n","Validation superclass acc: 88.72 %\n","\n","Epoch 13\n","Training loss: 0.128\n","Validation loss: 0.276\n","Validation superclass acc: 92.36 %\n","\n","Epoch 14\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-69d9c35d6684>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch+1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-70dab87c4508>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuper_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-5381904a8405>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msuper_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mann_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'superclass_index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# Training loop\n","print('Trainable parameters: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n","print('Total parameters: ', sum(p.numel() for p in model.parameters()))\n","print('----------------------')\n","print('')\n","for epoch in range(25):\n","    print(f'Epoch {epoch+1}')\n","    trainer.train_epoch()\n","    trainer.validate_epoch()\n","    print('')\n","    if epoch == 10:\n","      fine_tune(trainer.model.backbone)\n","      print('')\n","      print('Trainable parameters: ', sum(p.numel() for p in trainer.model.parameters() if p.requires_grad))\n","      print('Total parameters: ', sum(p.numel() for p in trainer.model.parameters()))\n","      print('----------------------')\n","      print('')\n","      trainer = Trainer(trainer.model, trainer.criterion, trainer.optimizer, trainer.train_loader, trainer.val_loader, trainer.test_loader)\n","\n","\n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"id":"16d17e37-1a08-4ae1-8517-a16ff4769622","metadata":{"id":"16d17e37-1a08-4ae1-8517-a16ff4769622","executionInfo":{"status":"aborted","timestamp":1702259239918,"user_tz":300,"elapsed":4,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["trainer.model.eval()\n","trainer.test(save_to_csv=False, return_predictions=True)\n","\n","'''\n","This simple baseline scores the following test accuracy\n","\n","Superclass Accuracy\n","Overall: 43.83 %\n","Seen: 61.11 %\n","Unseen: 0.00 %\n","\n","Subclass Accuracy\n","Overall: 2.03 %\n","Seen: 9.56 %\n","Unseen: 0.00 %\n","'''"]},{"cell_type":"code","execution_count":null,"id":"6ab70fb9-6e14-49f1-b9bb-5f3da6807399","metadata":{"id":"6ab70fb9-6e14-49f1-b9bb-5f3da6807399"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}