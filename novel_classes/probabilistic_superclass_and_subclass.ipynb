{"cells":[{"cell_type":"code","execution_count":1,"id":"198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3","metadata":{"id":"198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3","executionInfo":{"status":"ok","timestamp":1702304297851,"user_tz":300,"elapsed":8406,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["import os\n","import random\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import torchvision\n","\n","from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n","from torchvision import transforms\n","from PIL import Image"]},{"cell_type":"code","source":["super_prob_cut = 0.7 #probability cut-off for test image belonging to highest probability superclass from training data (if lower, classified as novel)\n","sub_prob_cut = 0.4 #probability cut-off for test image belonging to highest probability subclass from training data (if lower, classified as novel)\n"],"metadata":{"id":"nTDGpoNLGrh0","executionInfo":{"status":"ok","timestamp":1702304297851,"user_tz":300,"elapsed":3,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"id":"nTDGpoNLGrh0","execution_count":2,"outputs":[]},{"cell_type":"code","source":["from torchvision import models\n","backbone = models.resnet18(weights='IMAGENET1K_V1')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdTqQl3sTEgf","executionInfo":{"status":"ok","timestamp":1702304300069,"user_tz":300,"elapsed":2220,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"2995be26-c326-428e-9d64-204061aa5836"},"id":"SdTqQl3sTEgf","execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:01<00:00, 43.3MB/s]\n"]}]},{"cell_type":"code","source":["backbone"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpRXrXsNTQXn","executionInfo":{"status":"ok","timestamp":1702304300302,"user_tz":300,"elapsed":5,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"538ca86f-45dd-4e58-919e-092655eb7531"},"id":"cpRXrXsNTQXn","execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/NNDL_Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-yM4gnrFJ6l","executionInfo":{"status":"ok","timestamp":1702304316591,"user_tz":300,"elapsed":16292,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"9e7cdf6c-14af-41b2-8435-aa49fe90ec53"},"id":"x-yM4gnrFJ6l","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/NNDL_Project\n"]}]},{"cell_type":"code","source":["%%capture\n","! unzip -o train_shuffle.zip"],"metadata":{"id":"761mGvPYkeIV","executionInfo":{"status":"ok","timestamp":1702304421248,"user_tz":300,"elapsed":104661,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"id":"761mGvPYkeIV","execution_count":6,"outputs":[]},{"cell_type":"code","source":["%%capture\n","! unzip -o test_shuffle.zip"],"metadata":{"id":"7L3niCJakf41","executionInfo":{"status":"ok","timestamp":1702304529321,"user_tz":300,"elapsed":108077,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"id":"7L3niCJakf41","execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"id":"c370d643-46fd-4d03-bb17-a875e79d5e2c","metadata":{"id":"c370d643-46fd-4d03-bb17-a875e79d5e2c","executionInfo":{"status":"ok","timestamp":1702304529322,"user_tz":300,"elapsed":5,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["# Create Dataset class for multilabel classification\n","class MultiClassImageDataset(Dataset):\n","    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n","        self.ann_df = ann_df\n","        self.super_map_df = super_map_df\n","        self.sub_map_df = sub_map_df\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.ann_df)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.ann_df['image'][idx]\n","        img_path = os.path.join(self.img_dir, img_name)\n","        image = Image.open(img_path).convert('RGB')\n","\n","        super_idx = self.ann_df['superclass_index'][idx]\n","        super_label = self.super_map_df['class'][super_idx]\n","\n","        sub_idx = self.ann_df['subclass_index'][idx]\n","        sub_label = self.sub_map_df['class'][sub_idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, super_idx, super_label, sub_idx, sub_label\n","\n","class MultiClassImageTestDataset(Dataset):\n","    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n","        self.super_map_df = super_map_df\n","        self.sub_map_df = sub_map_df\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self): # Count files in img_dir\n","        return len([fname for fname in os.listdir(self.img_dir)])\n","\n","    def __getitem__(self, idx):\n","        img_name = str(idx) + '.jpg'\n","        img_path = os.path.join(self.img_dir, img_name)\n","        image = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, img_name"]},{"cell_type":"code","execution_count":9,"id":"e7398553-8842-4ad8-b348-767921a22482","metadata":{"id":"e7398553-8842-4ad8-b348-767921a22482","executionInfo":{"status":"ok","timestamp":1702304530656,"user_tz":300,"elapsed":1338,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["train_ann_df = pd.read_csv('train_data.csv')\n","super_map_df = pd.read_csv('superclass_mapping.csv')\n","sub_map_df = pd.read_csv('subclass_mapping.csv')\n","\n","train_img_dir = 'train_shuffle'\n","test_img_dir = 'test_shuffle'\n","\n","image_preprocessing = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0), std=(1)),\n","])\n","\n","# Create train and val split\n","train_dataset = MultiClassImageDataset(train_ann_df, super_map_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n","train_dataset, val_dataset = random_split(train_dataset, [0.9, 0.1])\n","\n","# Create test dataset\n","test_dataset = MultiClassImageTestDataset(super_map_df, sub_map_df, test_img_dir, transform=image_preprocessing)\n","\n","# Create dataloaders\n","batch_size = 64\n","train_loader = DataLoader(train_dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True, drop_last = True)\n","\n","val_loader = DataLoader(val_dataset,\n","                        batch_size=batch_size,\n","                        shuffle=True, drop_last = True)\n","\n","test_loader = DataLoader(test_dataset,\n","                         batch_size=1,\n","                         shuffle=False)"]},{"cell_type":"code","execution_count":91,"id":"bf33a131-0c66-40dc-b8d4-ba5d0f840840","metadata":{"id":"bf33a131-0c66-40dc-b8d4-ba5d0f840840","executionInfo":{"status":"ok","timestamp":1702308305931,"user_tz":300,"elapsed":156,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["# Simple CNN\n","class CNN(nn.Module):\n","    def __init__(self, backbone, finetune=False):\n","        super().__init__()\n","\n","        self.backbone = backbone\n","        num_ftrs = self.backbone.fc.in_features\n","        self.backbone.fc = torch.nn.Identity()\n","        for param in self.backbone.parameters():\n","          param.requires_grad = False\n","\n","        self.fca= nn.Linear(num_ftrs, 4)\n","        self.fcb= nn.Linear(num_ftrs, 88)\n","\n","\n","    def forward(self, x):\n","        x_new = self.backbone(x)\n","        super_out = self.fca(x_new)\n","        sub_out = self.fcb(x_new)\n","        return super_out, sub_out\n","\n","class Trainer():\n","    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n","        self.model = model\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.test_loader = test_loader\n","        self.device = device\n","        self.superclass_probs = {i:[] for i in range(4)}\n","        self.subclass_probs = {i:[] for i in range(88)}\n","\n","    def train_epoch(self):\n","        running_loss = 0.0\n","        device = self.device\n","        for i, data in enumerate(self.train_loader):\n","            inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n","\n","            self.optimizer.zero_grad()\n","            super_outputs, sub_outputs = self.model(inputs)\n","            loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f'Training loss: {running_loss/i:.3f}')\n","\n","    def validate_epoch(self, append_probs=False):\n","        super_correct = 0\n","        sub_correct = 0\n","        total = 0\n","        running_loss = 0.0\n","        device = self.device\n","        with torch.no_grad():\n","            for i, data in enumerate(self.val_loader):\n","                inputs, super_labels, sub_labels = data[0].to(device), data[1].to(device), data[3].to(device)\n","\n","                super_outputs, sub_outputs = self.model(inputs)\n","                loss = self.criterion(super_outputs, super_labels) + self.criterion(sub_outputs, sub_labels)\n","                _, super_predicted = torch.max(super_outputs.data, 1)\n","                _, sub_predicted = torch.max(sub_outputs.data, 1)\n","\n","                total += super_labels.size(0)\n","                super_correct += (super_predicted == super_labels).sum().item()\n","                sub_correct += (sub_predicted == sub_labels).sum().item()\n","                running_loss += loss.item()\n","\n","                if append_probs:\n","                  probs_super, classes_super = torch.max(torch.nn.functional.softmax(super_outputs.data, dim=1), dim=1)\n","                  for j, Class in enumerate(classes_super):\n","                    self.superclass_probs[Class.item()].append(probs_super[j])\n","\n","                  probs_sub, classes_sub = torch.max(torch.nn.functional.softmax(sub_outputs.data, dim=1), dim=1)\n","                  for j, Class in enumerate(classes_sub):\n","                    self.subclass_probs[Class.item()].append(probs_sub[j])\n","\n","            if append_probs:\n","              self.superclass_probs_mean = {k:torch.mean(torch.tensor(v)) for (k,v) in zip(self.superclass_probs.keys(), self.superclass_probs.values())}\n","              self.superclass_probs_sigma = {k:torch.std(torch.tensor(v)) for (k,v) in zip(self.superclass_probs.keys(), self.superclass_probs.values())}\n","              self.subclass_probs_mean = {k:torch.mean(torch.tensor(v)) for (k,v) in zip(self.subclass_probs.keys(), self.subclass_probs.values())}\n","              self.subclass_probs_sigma = {k:torch.std(torch.tensor(v)) for (k,v) in zip(self.subclass_probs.keys(), self.subclass_probs.values())}\n","              print(\"self.superclass_probs_mean: \", self.superclass_probs_mean)\n","              print(\"self.superclass_probs_sigma: \", self.superclass_probs_sigma)\n","              print(\"self.subclass_probs_mean: \", self.subclass_probs_mean)\n","              print(\"self.subclass_probs_sigma: \", self.subclass_probs_sigma)\n","\n","        print(f'Validation loss: {running_loss/i:.3f}')\n","        print(f'Validation superclass acc: {100 * super_correct / total:.2f} %')\n","        print(f'Validation subclass acc: {100 * sub_correct / total:.2f} %')\n","\n","    def test(self, save_to_csv=False, return_predictions=False):\n","        if not self.test_loader:\n","            raise NotImplementedError('test_loader not specified')\n","\n","\n","\n","        # decide on threshold probability cuts\n","\n","        z = 1.5\n","        mean_of_superclass_probs_mean = torch.nanmean(torch.tensor([self.superclass_probs_mean[k] for k in self.superclass_probs_mean], dtype=torch.float32))\n","        mean_of_superclass_probs_sigma = torch.nanmean(torch.tensor([self.superclass_probs_sigma[k] for k in self.superclass_probs_sigma], dtype=torch.float32))\n","        self.superclass_prob_thresholds = {}\n","        for i in range(4):\n","          if not torch.isnan(self.superclass_probs_mean[i]) and not torch.isnan(self.superclass_probs_sigma[i]):\n","            self.superclass_prob_thresholds[i] = self.superclass_probs_mean[i] - z*self.superclass_probs_sigma[i]\n","          else:\n","            self.superclass_prob_thresholds[i] = mean_of_superclass_probs_mean - z*mean_of_superclass_probs_sigma\n","        print('self.superclass_prob_thresholds: ', self.superclass_prob_thresholds)\n","\n","        mean_of_subclass_probs_mean = torch.nanmean(torch.tensor([self.subclass_probs_mean[k] for k in self.subclass_probs_mean], dtype=torch.float32))\n","        mean_of_subclass_probs_sigma = torch.nanmean(torch.tensor([self.subclass_probs_sigma[k] for k in self.subclass_probs_sigma], dtype=torch.float32))\n","        self.subclass_prob_thresholds = {}\n","        for i in range(88):\n","          if not torch.isnan(self.subclass_probs_mean[i]) and not torch.isnan(self.subclass_probs_sigma[i]):\n","            self.subclass_prob_thresholds[i] = self.subclass_probs_mean[i] - z*self.subclass_probs_sigma[i]\n","          else:\n","            self.subclass_prob_thresholds[i] = mean_of_subclass_probs_mean - z*mean_of_subclass_probs_sigma\n","        print('self.subclass_prob_thresholds: ', self.subclass_prob_thresholds)\n","\n","\n","\n","        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n","        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n","        with torch.no_grad():\n","            for i, data in enumerate(self.test_loader):\n","                inputs, img_name = data[0].to(device), data[1]\n","\n","                super_outputs, sub_outputs = self.model(inputs)\n","\n","                # if i < 50: #uncomment to get an idea of probabilities\n","                #   print('softmax super: ', torch.max(torch.nn.functional.softmax(super_outputs.data, dim=1)))\n","                #   print('softmax super beats cut: ', torch.max(torch.nn.functional.softmax(super_outputs.data, dim=1)) > super_prob_cut)\n","                #   print('softmax sub: ', torch.max(torch.nn.functional.softmax(sub_outputs.data, dim=1)))\n","                #   print('softmax sub beats cut: ', torch.max(torch.nn.functional.softmax(sub_outputs.data, dim=1)) > sub_prob_cut)\n","                #   print('')\n","                #   print('')\n","\n","                super_predicted = (torch.max(super_outputs.data, 1)[1]).item()\n","                sub_predicted = (torch.max(sub_outputs.data, 1)[1]).item()\n","                if torch.max(torch.nn.functional.softmax(super_outputs.data, dim=1)) < self.superclass_prob_thresholds[super_predicted]:\n","                  super_predicted = 3 #novel\n","                  sub_predicted = 87 #novel\n","                else:\n","                  if torch.max(torch.nn.functional.softmax(sub_outputs.data, dim=1)) < self.subclass_prob_thresholds[sub_predicted]:\n","                    sub_predicted = 87 #novel\n","                test_predictions['subclass_index'].append(sub_predicted)\n","                test_predictions['superclass_index'].append(super_predicted)\n","\n","\n","                test_predictions['image'].append(img_name[0])\n","\n","        test_predictions = pd.DataFrame(data=test_predictions)\n","\n","        if save_to_csv:\n","            test_predictions.to_csv('probabilistic_superandsub_test_predictions.csv', index=False)\n","\n","        if return_predictions:\n","            return test_predictions"]},{"cell_type":"code","source":["def fine_tune(backbone, cut):\n","  for i, layer in enumerate(backbone.children()):\n","    if i < cut: #just train last of the main convolutional layers\n","      for param in layer.parameters():\n","        param.requires_grad = False\n","    else:\n","      for param in layer.parameters():\n","        param.requires_grad = True\n","  return"],"metadata":{"id":"vTqAm1vX9fgt","executionInfo":{"status":"ok","timestamp":1702308306215,"user_tz":300,"elapsed":2,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"id":"vTqAm1vX9fgt","execution_count":92,"outputs":[]},{"cell_type":"code","execution_count":93,"id":"ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1","metadata":{"id":"ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1","executionInfo":{"status":"ok","timestamp":1702308306720,"user_tz":300,"elapsed":382,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[],"source":["# Init model and trainer\n","device = 'cuda'\n","backbone = models.resnet18(weights='IMAGENET1K_V1')\n","finetune = False\n","model = CNN(backbone, finetune=finetune).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"]},{"cell_type":"code","execution_count":94,"id":"7941c289-d9b1-4714-b788-898b3b889f58","metadata":{"id":"7941c289-d9b1-4714-b788-898b3b889f58","outputId":"b6ab27ab-26c8-44a1-e15e-d0c4624798fd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702308574216,"user_tz":300,"elapsed":267497,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable parameters:  47196\n","Total parameters:  11223708\n","----------------------\n","\n","Epoch 1\n","Training loss: 4.905\n","Validation loss: 4.672\n","Validation superclass acc: 72.22 %\n","Validation subclass acc: 19.62 %\n","\n","Epoch 2\n","Training loss: 3.737\n","Validation loss: 4.217\n","Validation superclass acc: 74.48 %\n","Validation subclass acc: 27.26 %\n","\n","Epoch 3\n","Training loss: 3.297\n","Validation loss: 4.124\n","Validation superclass acc: 73.61 %\n","Validation subclass acc: 24.83 %\n","\n","Epoch 4\n","Training loss: 3.051\n","Validation loss: 3.924\n","Validation superclass acc: 73.96 %\n","Validation subclass acc: 30.73 %\n","\n","Epoch 5\n","Training loss: 2.890\n","Validation loss: 4.058\n","Validation superclass acc: 72.40 %\n","Validation subclass acc: 30.03 %\n","\n","Epoch 6\n","Training loss: 2.720\n","Validation loss: 3.933\n","Validation superclass acc: 73.09 %\n","Validation subclass acc: 29.51 %\n","\n","Epoch 7\n","Training loss: 2.633\n","Validation loss: 3.934\n","Validation superclass acc: 75.69 %\n","Validation subclass acc: 31.42 %\n","\n","Epoch 8\n","Training loss: 2.545\n","Validation loss: 3.921\n","Validation superclass acc: 72.74 %\n","Validation subclass acc: 31.25 %\n","\n","Epoch 9\n","Training loss: 2.507\n","Validation loss: 3.998\n","Validation superclass acc: 74.65 %\n","Validation subclass acc: 30.38 %\n","\n","Epoch 10\n","Training loss: 2.417\n","Validation loss: 3.965\n","Validation superclass acc: 74.83 %\n","Validation subclass acc: 34.03 %\n","\n","Epoch 11\n","Training loss: 2.363\n","Validation loss: 3.895\n","Validation superclass acc: 75.69 %\n","Validation subclass acc: 30.90 %\n","\n","\n","Trainable parameters:  10540636\n","Total parameters:  11223708\n","----------------------\n","\n","Epoch 12\n","Training loss: 2.783\n","Validation loss: 2.215\n","Validation superclass acc: 93.06 %\n","Validation subclass acc: 49.13 %\n","\n","Epoch 13\n","Training loss: 1.512\n","Validation loss: 2.194\n","Validation superclass acc: 92.88 %\n","Validation subclass acc: 50.69 %\n","\n","Epoch 14\n","Training loss: 1.032\n","Validation loss: 2.088\n","Validation superclass acc: 93.40 %\n","Validation subclass acc: 57.64 %\n","\n","Epoch 15\n","Training loss: 0.759\n","Validation loss: 2.262\n","Validation superclass acc: 93.06 %\n","Validation subclass acc: 52.78 %\n","\n","Epoch 16\n","Training loss: 0.629\n","Validation loss: 2.230\n","Validation superclass acc: 93.06 %\n","Validation subclass acc: 59.38 %\n","\n","Epoch 17\n","Training loss: 0.497\n","Validation loss: 2.155\n","Validation superclass acc: 94.27 %\n","Validation subclass acc: 58.68 %\n","\n","Epoch 18\n","Training loss: 0.364\n","Validation loss: 2.338\n","Validation superclass acc: 93.58 %\n","Validation subclass acc: 59.20 %\n","\n","Epoch 19\n","Training loss: 0.284\n","Validation loss: 2.520\n","Validation superclass acc: 94.44 %\n","Validation subclass acc: 57.64 %\n","\n","Epoch 20\n","Training loss: 0.299\n","Validation loss: 2.357\n","Validation superclass acc: 93.40 %\n","Validation subclass acc: 60.24 %\n","\n","Epoch 21\n","Training loss: 0.219\n","Validation loss: 2.280\n","Validation superclass acc: 94.79 %\n","Validation subclass acc: 63.19 %\n","\n","\n","Trainable parameters:  11066204\n","Total parameters:  11223708\n","----------------------\n","\n","Epoch 22\n","Training loss: 0.906\n","Validation loss: 2.344\n","Validation superclass acc: 93.58 %\n","Validation subclass acc: 56.77 %\n","\n","Epoch 23\n","Training loss: 0.596\n","Validation loss: 1.907\n","Validation superclass acc: 96.18 %\n","Validation subclass acc: 64.41 %\n","\n","Epoch 24\n","Training loss: 0.423\n","Validation loss: 2.314\n","Validation superclass acc: 93.75 %\n","Validation subclass acc: 60.42 %\n","\n","Epoch 25\n","Training loss: 0.246\n","self.superclass_probs_mean:  {0: tensor(0.9706), 1: tensor(0.9750), 2: tensor(0.9792), 3: tensor(nan)}\n","self.superclass_probs_sigma:  {0: tensor(0.0902), 1: tensor(0.0809), 2: tensor(0.0766), 3: tensor(nan)}\n","self.subclass_probs_mean:  {0: tensor(0.7409), 1: tensor(0.9125), 2: tensor(0.7418), 3: tensor(0.7511), 4: tensor(0.8745), 5: tensor(0.8939), 6: tensor(0.8523), 7: tensor(0.8577), 8: tensor(0.7712), 9: tensor(0.6734), 10: tensor(0.7657), 11: tensor(0.8526), 12: tensor(0.6462), 13: tensor(0.7507), 14: tensor(0.6640), 15: tensor(0.6821), 16: tensor(0.7740), 17: tensor(nan), 18: tensor(0.7920), 19: tensor(0.9141), 20: tensor(0.8370), 21: tensor(0.8202), 22: tensor(0.6623), 23: tensor(0.6398), 24: tensor(0.9198), 25: tensor(0.6887), 26: tensor(0.7559), 27: tensor(0.8629), 28: tensor(0.9779), 29: tensor(0.8350), 30: tensor(0.9028), 31: tensor(0.7848), 32: tensor(0.7052), 33: tensor(0.7865), 34: tensor(0.9897), 35: tensor(0.8627), 36: tensor(0.9025), 37: tensor(0.7718), 38: tensor(0.6976), 39: tensor(0.8939), 40: tensor(0.9031), 41: tensor(0.8833), 42: tensor(0.8411), 43: tensor(0.9040), 44: tensor(0.9781), 45: tensor(0.8712), 46: tensor(0.8850), 47: tensor(0.6905), 48: tensor(0.5060), 49: tensor(0.6515), 50: tensor(0.9843), 51: tensor(0.9392), 52: tensor(0.7727), 53: tensor(0.8123), 54: tensor(0.8433), 55: tensor(0.6313), 56: tensor(0.8557), 57: tensor(0.8609), 58: tensor(0.6404), 59: tensor(0.9867), 60: tensor(0.7616), 61: tensor(0.9187), 62: tensor(0.9593), 63: tensor(0.7774), 64: tensor(0.7482), 65: tensor(0.9182), 66: tensor(0.9498), 67: tensor(0.9075), 68: tensor(0.7201), 69: tensor(0.7849), 70: tensor(0.8911), 71: tensor(0.7909), 72: tensor(0.9352), 73: tensor(0.8281), 74: tensor(0.9732), 75: tensor(0.8998), 76: tensor(0.8604), 77: tensor(0.7421), 78: tensor(0.9997), 79: tensor(0.8021), 80: tensor(0.8515), 81: tensor(0.7902), 82: tensor(0.9667), 83: tensor(0.9212), 84: tensor(0.9804), 85: tensor(0.6852), 86: tensor(0.8262), 87: tensor(nan)}\n","self.subclass_probs_sigma:  {0: tensor(0.2495), 1: tensor(0.1617), 2: tensor(0.2739), 3: tensor(0.2068), 4: tensor(0.2317), 5: tensor(0.0935), 6: tensor(0.2058), 7: tensor(0.2479), 8: tensor(0.2423), 9: tensor(0.3109), 10: tensor(0.2709), 11: tensor(0.0228), 12: tensor(0.4402), 13: tensor(0.3515), 14: tensor(0.1932), 15: tensor(nan), 16: tensor(0.3100), 17: tensor(nan), 18: tensor(0.3585), 19: tensor(0.1194), 20: tensor(0.1999), 21: tensor(0.2572), 22: tensor(0.2936), 23: tensor(0.2030), 24: tensor(0.1389), 25: tensor(0.4335), 26: tensor(0.1753), 27: tensor(0.1874), 28: tensor(0.0530), 29: tensor(0.2514), 30: tensor(0.2224), 31: tensor(0.2872), 32: tensor(0.2474), 33: tensor(0.2177), 34: tensor(0.0167), 35: tensor(0.2458), 36: tensor(0.2295), 37: tensor(0.2258), 38: tensor(0.2370), 39: tensor(0.1300), 40: tensor(0.1348), 41: tensor(0.2160), 42: tensor(0.2319), 43: tensor(0.1683), 44: tensor(0.0605), 45: tensor(0.1797), 46: tensor(0.1359), 47: tensor(0.2639), 48: tensor(nan), 49: tensor(0.2654), 50: tensor(0.0382), 51: tensor(0.0931), 52: tensor(0.2748), 53: tensor(0.1806), 54: tensor(0.0604), 55: tensor(0.3289), 56: tensor(0.2036), 57: tensor(0.1956), 58: tensor(0.2707), 59: tensor(0.0276), 60: tensor(0.4093), 61: tensor(0.1257), 62: tensor(0.1115), 63: tensor(0.2110), 64: tensor(0.2400), 65: tensor(0.1333), 66: tensor(0.0938), 67: tensor(0.1306), 68: tensor(0.0616), 69: tensor(0.2453), 70: tensor(0.0997), 71: tensor(0.2351), 72: tensor(0.1441), 73: tensor(0.2307), 74: tensor(nan), 75: tensor(0.1189), 76: tensor(0.1979), 77: tensor(0.2079), 78: tensor(0.0008), 79: tensor(0.2325), 80: tensor(0.2344), 81: tensor(0.1574), 82: tensor(0.0374), 83: tensor(0.1368), 84: tensor(0.0428), 85: tensor(0.2556), 86: tensor(0.2027), 87: tensor(nan)}\n","Validation loss: 2.191\n","Validation superclass acc: 95.14 %\n","Validation subclass acc: 64.93 %\n","\n","Finished Training\n"]}],"source":["# Training loop\n","print('Trainable parameters: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n","print('Total parameters: ', sum(p.numel() for p in model.parameters()))\n","print('----------------------')\n","print('')\n","Nepochs = 25\n","for epoch in range(Nepochs):\n","    print(f'Epoch {epoch+1}')\n","    trainer.train_epoch()\n","    if epoch == Nepochs-1:\n","      trainer.validate_epoch(append_probs=True)\n","    else:\n","      trainer.validate_epoch(append_probs=False)\n","    print('')\n","    if epoch == 10:\n","      fine_tune(trainer.model.backbone, 6)\n","      print('')\n","      print('Trainable parameters: ', sum(p.numel() for p in trainer.model.parameters() if p.requires_grad))\n","      print('Total parameters: ', sum(p.numel() for p in trainer.model.parameters()))\n","      print('----------------------')\n","      print('')\n","      trainer = Trainer(trainer.model, trainer.criterion, trainer.optimizer, trainer.train_loader, trainer.val_loader, trainer.test_loader)\n","    elif epoch == 20:\n","      fine_tune(trainer.model.backbone, 5)\n","      print('')\n","      print('Trainable parameters: ', sum(p.numel() for p in trainer.model.parameters() if p.requires_grad))\n","      print('Total parameters: ', sum(p.numel() for p in trainer.model.parameters()))\n","      print('----------------------')\n","      print('')\n","      trainer = Trainer(trainer.model, trainer.criterion, trainer.optimizer, trainer.train_loader, trainer.val_loader, trainer.test_loader)\n","\n","\n","print('Finished Training')"]},{"cell_type":"code","execution_count":95,"id":"16d17e37-1a08-4ae1-8517-a16ff4769622","metadata":{"id":"16d17e37-1a08-4ae1-8517-a16ff4769622","colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"status":"ok","timestamp":1702308676127,"user_tz":300,"elapsed":101916,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"f8c0d2d3-9ee4-473a-a970-1bf3c3d5c93b"},"outputs":[{"output_type":"stream","name":"stdout","text":["self.superclass_prob_thresholds:  {0: tensor(0.8353), 1: tensor(0.8536), 2: tensor(0.8643), 3: tensor(0.8511)}\n","self.subclass_prob_thresholds:  {0: tensor(0.3666), 1: tensor(0.6700), 2: tensor(0.3309), 3: tensor(0.4409), 4: tensor(0.5270), 5: tensor(0.7537), 6: tensor(0.5436), 7: tensor(0.4859), 8: tensor(0.4078), 9: tensor(0.2070), 10: tensor(0.3593), 11: tensor(0.8184), 12: tensor(-0.0142), 13: tensor(0.2234), 14: tensor(0.3742), 15: tensor(0.5315), 16: tensor(0.3090), 17: tensor(0.5315), 18: tensor(0.2541), 19: tensor(0.7350), 20: tensor(0.5372), 21: tensor(0.4343), 22: tensor(0.2219), 23: tensor(0.3353), 24: tensor(0.7114), 25: tensor(0.0385), 26: tensor(0.4928), 27: tensor(0.5819), 28: tensor(0.8984), 29: tensor(0.4579), 30: tensor(0.5693), 31: tensor(0.3541), 32: tensor(0.3341), 33: tensor(0.4599), 34: tensor(0.9646), 35: tensor(0.4940), 36: tensor(0.5582), 37: tensor(0.4331), 38: tensor(0.3421), 39: tensor(0.6989), 40: tensor(0.7010), 41: tensor(0.5593), 42: tensor(0.4933), 43: tensor(0.6516), 44: tensor(0.8873), 45: tensor(0.6015), 46: tensor(0.6812), 47: tensor(0.2945), 48: tensor(0.5315), 49: tensor(0.2534), 50: tensor(0.9269), 51: tensor(0.7996), 52: tensor(0.3605), 53: tensor(0.5414), 54: tensor(0.7527), 55: tensor(0.1379), 56: tensor(0.5503), 57: tensor(0.5675), 58: tensor(0.2343), 59: tensor(0.9454), 60: tensor(0.1477), 61: tensor(0.7302), 62: tensor(0.7921), 63: tensor(0.4609), 64: tensor(0.3883), 65: tensor(0.7182), 66: tensor(0.8091), 67: tensor(0.7116), 68: tensor(0.6277), 69: tensor(0.4169), 70: tensor(0.7415), 71: tensor(0.4382), 72: tensor(0.7191), 73: tensor(0.4821), 74: tensor(0.5315), 75: tensor(0.7214), 76: tensor(0.5635), 77: tensor(0.4302), 78: tensor(0.9985), 79: tensor(0.4534), 80: tensor(0.4999), 81: tensor(0.5541), 82: tensor(0.9106), 83: tensor(0.7161), 84: tensor(0.9162), 85: tensor(0.3017), 86: tensor(0.5221), 87: tensor(0.5315)}\n"]},{"output_type":"execute_result","data":{"text/plain":["'\\nThis simple baseline scores the following test accuracy\\n\\nSuperclass Accuracy\\nOverall: 43.83 %\\nSeen: 61.11 %\\nUnseen: 0.00 %\\n\\nSubclass Accuracy\\nOverall: 2.03 %\\nSeen: 9.56 %\\nUnseen: 0.00 %\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":95}],"source":["trainer.model.eval()\n","predictions = trainer.test(save_to_csv=True, return_predictions=True)\n","\n","'''\n","This simple baseline scores the following test accuracy\n","\n","Superclass Accuracy\n","Overall: 43.83 %\n","Seen: 61.11 %\n","Unseen: 0.00 %\n","\n","Subclass Accuracy\n","Overall: 2.03 %\n","Seen: 9.56 %\n","Unseen: 0.00 %\n","'''"]},{"cell_type":"code","source":["predictions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"TT4QR2MgIwWc","executionInfo":{"status":"ok","timestamp":1702308676127,"user_tz":300,"elapsed":12,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"7587234d-df4e-4603-df85-c1325d077bb0"},"id":"TT4QR2MgIwWc","execution_count":96,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           image  superclass_index  subclass_index\n","0          0.jpg                 1              17\n","1          1.jpg                 0              86\n","2          2.jpg                 2              29\n","3          3.jpg                 3              87\n","4          4.jpg                 1              64\n","...          ...               ...             ...\n","12372  12372.jpg                 0               6\n","12373  12373.jpg                 2              87\n","12374  12374.jpg                 2              44\n","12375  12375.jpg                 2              47\n","12376  12376.jpg                 1              87\n","\n","[12377 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-209fbb5c-23b4-4f4a-968e-2307d973088c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>superclass_index</th>\n","      <th>subclass_index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.jpg</td>\n","      <td>1</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.jpg</td>\n","      <td>0</td>\n","      <td>86</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.jpg</td>\n","      <td>2</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3.jpg</td>\n","      <td>3</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4.jpg</td>\n","      <td>1</td>\n","      <td>64</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12372</th>\n","      <td>12372.jpg</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>12373</th>\n","      <td>12373.jpg</td>\n","      <td>2</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>12374</th>\n","      <td>12374.jpg</td>\n","      <td>2</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>12375</th>\n","      <td>12375.jpg</td>\n","      <td>2</td>\n","      <td>47</td>\n","    </tr>\n","    <tr>\n","      <th>12376</th>\n","      <td>12376.jpg</td>\n","      <td>1</td>\n","      <td>87</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>12377 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-209fbb5c-23b4-4f4a-968e-2307d973088c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-209fbb5c-23b4-4f4a-968e-2307d973088c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-209fbb5c-23b4-4f4a-968e-2307d973088c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3c16f304-db0b-4a2e-b225-90420859b998\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3c16f304-db0b-4a2e-b225-90420859b998')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3c16f304-db0b-4a2e-b225-90420859b998 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","execution_count":97,"id":"6ab70fb9-6e14-49f1-b9bb-5f3da6807399","metadata":{"id":"6ab70fb9-6e14-49f1-b9bb-5f3da6807399","executionInfo":{"status":"ok","timestamp":1702308676127,"user_tz":300,"elapsed":10,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"colab":{"base_uri":"https://localhost:8080/","height":424},"outputId":"4b30240b-7120-45f2-8614-af3750219c62"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["           image  superclass_index  subclass_index\n","1          1.jpg                 0              86\n","6          6.jpg                 0              24\n","8          8.jpg                 0              87\n","11        11.jpg                 0              87\n","12        12.jpg                 0              85\n","...          ...               ...             ...\n","12360  12360.jpg                 0              87\n","12361  12361.jpg                 0              87\n","12362  12362.jpg                 0              41\n","12369  12369.jpg                 0              87\n","12372  12372.jpg                 0               6\n","\n","[3779 rows x 3 columns]"],"text/html":["\n","  <div id=\"df-01c3c4e8-ab7e-4fa0-8847-598158d3f81c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>superclass_index</th>\n","      <th>subclass_index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1.jpg</td>\n","      <td>0</td>\n","      <td>86</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6.jpg</td>\n","      <td>0</td>\n","      <td>24</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8.jpg</td>\n","      <td>0</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11.jpg</td>\n","      <td>0</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12.jpg</td>\n","      <td>0</td>\n","      <td>85</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>12360</th>\n","      <td>12360.jpg</td>\n","      <td>0</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>12361</th>\n","      <td>12361.jpg</td>\n","      <td>0</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>12362</th>\n","      <td>12362.jpg</td>\n","      <td>0</td>\n","      <td>41</td>\n","    </tr>\n","    <tr>\n","      <th>12369</th>\n","      <td>12369.jpg</td>\n","      <td>0</td>\n","      <td>87</td>\n","    </tr>\n","    <tr>\n","      <th>12372</th>\n","      <td>12372.jpg</td>\n","      <td>0</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3779 rows × 3 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01c3c4e8-ab7e-4fa0-8847-598158d3f81c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-01c3c4e8-ab7e-4fa0-8847-598158d3f81c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-01c3c4e8-ab7e-4fa0-8847-598158d3f81c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-6f06c33e-f476-4499-b287-ac337ae5ec2e\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f06c33e-f476-4499-b287-ac337ae5ec2e')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-6f06c33e-f476-4499-b287-ac337ae5ec2e button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":97}],"source":["predictions[predictions['superclass_index']==0]"]},{"cell_type":"code","source":["predictions['superclass_index'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O4ttXMj2Ky2h","executionInfo":{"status":"ok","timestamp":1702308676127,"user_tz":300,"elapsed":9,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"8f810990-7eb9-49a0-f4f2-b44fe327560c"},"id":"O4ttXMj2Ky2h","execution_count":98,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    3779\n","1    3649\n","2    2907\n","3    2042\n","Name: superclass_index, dtype: int64"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["predictions['subclass_index'].value_counts()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lVSPnVM7LCHN","executionInfo":{"status":"ok","timestamp":1702308676127,"user_tz":300,"elapsed":8,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"46cef525-3ad4-45da-f0a5-6be91ea66d2e"},"id":"lVSPnVM7LCHN","execution_count":99,"outputs":[{"output_type":"execute_result","data":{"text/plain":["87    4485\n","52     231\n","44     222\n","77     206\n","64     197\n","      ... \n","67      19\n","61      18\n","50      15\n","66      15\n","75       7\n","Name: subclass_index, Length: 88, dtype: int64"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":[],"metadata":{"id":"cRWnQUIfLEP6"},"id":"cRWnQUIfLEP6","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}