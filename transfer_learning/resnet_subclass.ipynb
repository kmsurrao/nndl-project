{"cells":[{"cell_type":"code","execution_count":null,"id":"198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3","metadata":{"id":"198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3"},"outputs":[],"source":["import os\n","import random\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","import torchvision\n","\n","from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n","from torchvision import transforms\n","from PIL import Image"]},{"cell_type":"code","source":["# Train only subclass classification for a given superclass\n","superclass_idx = 0 # 0 for dog, 1 for bird, 2 for reptile\n","superclass_test_img_dir = '' # fill in with path to directory containing only test images predicted to belong to superclass corresponding to superclass_idx"],"metadata":{"id":"7gpdElokxhev"},"id":"7gpdElokxhev","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision import models\n","backbone = models.resnet18(weights='IMAGENET1K_V1')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SdTqQl3sTEgf","executionInfo":{"status":"ok","timestamp":1702250512197,"user_tz":300,"elapsed":1363,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"4ea97f96-8b32-4a78-a9f8-1d32de3e5f71"},"id":"SdTqQl3sTEgf","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:00<00:00, 56.2MB/s]\n"]}]},{"cell_type":"code","source":["backbone"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cpRXrXsNTQXn","executionInfo":{"status":"ok","timestamp":1702250512395,"user_tz":300,"elapsed":202,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"cef3e7a7-2d66-4210-e7d6-302024919103"},"id":"cpRXrXsNTQXn","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/NNDL_Project"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x-yM4gnrFJ6l","executionInfo":{"status":"ok","timestamp":1702250527148,"user_tz":300,"elapsed":14756,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}},"outputId":"5c5cd8c5-cca8-49f7-c11a-2ec750d13460"},"id":"x-yM4gnrFJ6l","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/NNDL_Project\n"]}]},{"cell_type":"code","source":["%%capture\n","! unzip -o train_shuffle.zip"],"metadata":{"id":"17Sd6rn4kwu8"},"id":"17Sd6rn4kwu8","execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","! unzip -o test_shuffle.zip"],"metadata":{"id":"19JJ2-QSkxyq"},"id":"19JJ2-QSkxyq","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"c370d643-46fd-4d03-bb17-a875e79d5e2c","metadata":{"id":"c370d643-46fd-4d03-bb17-a875e79d5e2c"},"outputs":[],"source":["# Create Dataset class for multilabel classification\n","class MultiClassImageDataset(Dataset):\n","    def __init__(self, ann_df, sub_map_df, img_dir, transform=None):\n","        self.ann_df = ann_df\n","        self.sub_map_df = sub_map_df\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.ann_df)\n","\n","    def __getitem__(self, idx):\n","        img_name = self.ann_df['image'][idx]\n","        img_path = os.path.join(self.img_dir, img_name)\n","        image = Image.open(img_path).convert('RGB')\n","\n","        sub_idx = self.ann_df['subclass_index'][idx]\n","        sub_label = self.sub_map_df['class'][sub_idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, sub_idx, sub_label\n","\n","class MultiClassImageTestDataset(Dataset):\n","    def __init__(self, sub_map_df, img_dir, transform=None):\n","        self.sub_map_df = sub_map_df\n","        self.img_dir = img_dir\n","        self.transform = transform\n","\n","    def __len__(self): # Count files in img_dir\n","        return len([fname for fname in os.listdir(self.img_dir)])\n","\n","    def __getitem__(self, idx):\n","        img_name = str(idx) + '.jpg'\n","        img_path = os.path.join(self.img_dir, img_name)\n","        image = Image.open(img_path).convert('RGB')\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        return image, img_name"]},{"cell_type":"code","execution_count":null,"id":"e7398553-8842-4ad8-b348-767921a22482","metadata":{"id":"e7398553-8842-4ad8-b348-767921a22482"},"outputs":[],"source":["train_ann_df = pd.read_csv('train_data.csv')\n","train_ann_df = train_ann_df[train_ann_df['superclass_index'] == superclass_idx]\n","train_ann_df = train_ann_df.reset_index(drop=True)\n","\n","super_map_df = pd.read_csv('superclass_mapping.csv')\n","sub_map_df = pd.read_csv('subclass_mapping.csv')\n","\n","train_img_dir = 'train_shuffle'\n","test_img_dir = 'test_shuffle'\n","\n","image_preprocessing = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=(0), std=(1)),\n","])\n","\n","# Create train and val split\n","train_dataset = MultiClassImageDataset(train_ann_df, sub_map_df, train_img_dir, transform=image_preprocessing)\n","train_dataset, val_dataset = random_split(train_dataset, [0.9, 0.1])\n","\n","# Create test dataset\n","test_dataset = MultiClassImageTestDataset(sub_map_df, superclass_test_img_dir, transform=image_preprocessing)\n","\n","# Create dataloaders\n","batch_size = 64\n","train_loader = DataLoader(train_dataset,\n","                          batch_size=batch_size,\n","                          shuffle=True, drop_last = True)\n","\n","val_loader = DataLoader(val_dataset,\n","                        batch_size=batch_size,\n","                        shuffle=True, drop_last = True)\n","\n","test_loader = DataLoader(test_dataset,\n","                         batch_size=1,\n","                         shuffle=False)"]},{"cell_type":"code","execution_count":null,"id":"bf33a131-0c66-40dc-b8d4-ba5d0f840840","metadata":{"id":"bf33a131-0c66-40dc-b8d4-ba5d0f840840"},"outputs":[],"source":["# Simple CNN\n","class CNN(nn.Module):\n","    def __init__(self, backbone, finetune=False):\n","        super().__init__()\n","\n","        self.backbone = backbone\n","        if not finetune:\n","          for param in self.backbone.parameters():\n","            param.requires_grad = False\n","        else:\n","          for i, layer in enumerate(backbone.children()):\n","            if i < 6: #just train last of the main convolutional layers\n","              for param in layer.parameters():\n","                param.requires_grad = False\n","            else:\n","              for param in layer.parameters():\n","                param.requires_grad = True\n","\n","\n","        num_ftrs = self.backbone.fc.in_features\n","        # Here the size of each output sample is set to 2.\n","        # Alternatively, it can be generalized to ``nn.Linear(num_ftrs, len(class_names))``.\n","        self.backbone.fc = nn.Linear(num_ftrs, 88)\n","\n","    def forward(self, x):\n","        sub_out = self.backbone(x)\n","        return sub_out\n","\n","class Trainer():\n","    def __init__(self, model, criterion, optimizer, train_loader, val_loader, test_loader=None, device='cuda'):\n","        self.model = model\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.test_loader = test_loader\n","        self.device = device\n","\n","    def train_epoch(self):\n","        running_loss = 0.0\n","        device = self.device\n","        for i, data in enumerate(self.train_loader):\n","            inputs, sub_labels = data[0].to(device), data[1].to(device)\n","\n","            self.optimizer.zero_grad()\n","            sub_outputs = self.model(inputs)\n","            loss = self.criterion(sub_outputs, sub_labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item()\n","\n","        print(f'Training loss: {running_loss/i:.3f}')\n","\n","    def validate_epoch(self):\n","        sub_correct = 0\n","        total = 0\n","        running_loss = 0.0\n","        device = self.device\n","        with torch.no_grad():\n","            for i, data in enumerate(self.val_loader):\n","                inputs, sub_labels = data[0].to(device), data[1].to(device)\n","\n","                sub_outputs = self.model(inputs)\n","                loss = self.criterion(sub_outputs, sub_labels)\n","                _, sub_predicted = torch.max(sub_outputs.data, 1)\n","\n","                total += sub_labels.size(0)\n","                sub_correct += (sub_predicted == sub_labels).sum().item()\n","                running_loss += loss.item()\n","\n","        print(f'Validation loss: {running_loss/i:.3f}')\n","        print(f'Validation subclass acc: {100 * sub_correct / total:.2f} %')\n","\n","    def test(self, save_to_csv=False, return_predictions=False):\n","        if not self.test_loader:\n","            raise NotImplementedError('test_loader not specified')\n","\n","        # Evaluate on test set, in this simple demo no special care is taken for novel/unseen classes\n","        test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n","        with torch.no_grad():\n","            for i, data in enumerate(self.test_loader):\n","                inputs, img_name = data[0].to(device), data[1]\n","\n","                sub_outputs = self.model(inputs)\n","                _, sub_predicted = torch.max(sub_outputs.data, 1)\n","\n","                test_predictions['image'].append(img_name[0])\n","                test_predictions['subclass_index'].append(sub_predicted.item())\n","\n","        test_predictions = pd.DataFrame(data=test_predictions)\n","\n","        if save_to_csv:\n","            test_predictions.to_csv(f'test_predictions_transferlearning_subclass_superclass{superclass_idx}.csv', index=False)\n","\n","        if return_predictions:\n","            return test_predictions"]},{"cell_type":"code","source":["def fine_tune(backbone):\n","  for i, layer in enumerate(backbone.children()):\n","    if i < 6: #just train last of the main convolutional layers\n","      for param in layer.parameters():\n","        param.requires_grad = False\n","    else:\n","      for param in layer.parameters():\n","        param.requires_grad = True\n","  return"],"metadata":{"id":"vTqAm1vX9fgt"},"id":"vTqAm1vX9fgt","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1","metadata":{"id":"ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1"},"outputs":[],"source":["# Init model and trainer\n","device = 'cuda'\n","backbone = models.resnet18(weights='IMAGENET1K_V1')\n","finetune = False\n","model = CNN(backbone, finetune=finetune).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","trainer = Trainer(model, criterion, optimizer, train_loader, val_loader, test_loader)"]},{"cell_type":"code","execution_count":null,"id":"7941c289-d9b1-4714-b788-898b3b889f58","metadata":{"id":"7941c289-d9b1-4714-b788-898b3b889f58","outputId":"91ad24f9-b89c-440e-c5fa-509d36cfb131","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702251312438,"user_tz":300,"elapsed":73586,"user":{"displayName":"Kristen Marie Surrao","userId":"04768648551870469797"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Trainable parameters:  45144\n","Total parameters:  11221656\n","Epoch 1\n","Training loss: 3.609\n","Validation loss: 6.007\n","Validation subclass acc: 21.09 %\n","\n","Epoch 2\n","Training loss: 2.711\n","Validation loss: 5.155\n","Validation subclass acc: 29.69 %\n","\n","Epoch 3\n","Training loss: 2.318\n","Validation loss: 4.814\n","Validation subclass acc: 29.69 %\n","\n","Epoch 4\n","Training loss: 2.056\n","Validation loss: 4.421\n","Validation subclass acc: 39.06 %\n","\n","Epoch 5\n","Training loss: 1.874\n","Validation loss: 4.424\n","Validation subclass acc: 32.81 %\n","\n","Epoch 6\n","Training loss: 1.747\n","Validation loss: 4.117\n","Validation subclass acc: 38.28 %\n","\n","Epoch 7\n","Training loss: 1.640\n","Validation loss: 4.167\n","Validation subclass acc: 39.84 %\n","\n","Epoch 8\n","Training loss: 1.538\n","Validation loss: 4.012\n","Validation subclass acc: 39.84 %\n","\n","Epoch 9\n","Training loss: 1.503\n","Validation loss: 3.997\n","Validation subclass acc: 45.31 %\n","\n","Epoch 10\n","Training loss: 1.438\n","Validation loss: 4.204\n","Validation subclass acc: 35.16 %\n","\n","Epoch 11\n","Training loss: 1.380\n","Validation loss: 4.044\n","Validation subclass acc: 40.62 %\n","\n","Epoch 12\n","Training loss: 1.302\n","Validation loss: 3.966\n","Validation subclass acc: 42.97 %\n","\n","Epoch 13\n","Training loss: 1.275\n","Validation loss: 3.903\n","Validation subclass acc: 44.53 %\n","\n","Epoch 14\n","Training loss: 1.254\n","Validation loss: 3.951\n","Validation subclass acc: 43.75 %\n","\n","Epoch 15\n","Training loss: 1.217\n","Validation loss: 3.788\n","Validation subclass acc: 38.28 %\n","\n","Epoch 16\n","Training loss: 1.180\n","Validation loss: 4.210\n","Validation subclass acc: 46.09 %\n","\n","\n","Trainable parameters:  10538584\n","Total parameters:  11221656\n","\n","Epoch 17\n","Training loss: 1.870\n","Validation loss: 2.568\n","Validation subclass acc: 60.16 %\n","\n","Epoch 18\n","Training loss: 0.715\n","Validation loss: 2.545\n","Validation subclass acc: 64.06 %\n","\n","Epoch 19\n","Training loss: 0.339\n","Validation loss: 2.809\n","Validation subclass acc: 65.62 %\n","\n","Epoch 20\n","Training loss: 0.209\n","Validation loss: 3.040\n","Validation subclass acc: 64.06 %\n","\n","Epoch 21\n","Training loss: 0.128\n","Validation loss: 3.003\n","Validation subclass acc: 66.41 %\n","\n","Epoch 22\n","Training loss: 0.129\n","Validation loss: 3.197\n","Validation subclass acc: 64.84 %\n","\n","Epoch 23\n","Training loss: 0.143\n","Validation loss: 3.304\n","Validation subclass acc: 64.06 %\n","\n","Epoch 24\n","Training loss: 0.134\n","Validation loss: 3.924\n","Validation subclass acc: 59.38 %\n","\n","Epoch 25\n","Training loss: 0.166\n","Validation loss: 3.084\n","Validation subclass acc: 67.97 %\n","\n","Finished Training\n"]}],"source":["# Training loop\n","print('Trainable parameters: ', sum(p.numel() for p in model.parameters() if p.requires_grad))\n","print('Total parameters: ', sum(p.numel() for p in model.parameters()))\n","print('----------------------')\n","print('')\n","for epoch in range(25):\n","    print(f'Epoch {epoch+1}')\n","    trainer.train_epoch()\n","    trainer.validate_epoch()\n","    print('')\n","    if epoch == 10:\n","      fine_tune(trainer.model.backbone)\n","      print('')\n","      print('Trainable parameters: ', sum(p.numel() for p in trainer.model.parameters() if p.requires_grad))\n","      print('Total parameters: ', sum(p.numel() for p in trainer.model.parameters()))\n","      print('----------------------')\n","      print('')\n","      trainer = Trainer(trainer.model, trainer.criterion, trainer.optimizer, trainer.train_loader, trainer.val_loader, trainer.test_loader)\n","\n","\n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"id":"6ab70fb9-6e14-49f1-b9bb-5f3da6807399","metadata":{"id":"6ab70fb9-6e14-49f1-b9bb-5f3da6807399"},"outputs":[],"source":["trainer.model.eval()\n","trainer.test(save_to_csv=False, return_predictions=True)\n","\n","'''\n","This simple baseline scores the following test accuracy\n","\n","Superclass Accuracy\n","Overall: 43.83 %\n","Seen: 61.11 %\n","Unseen: 0.00 %\n","\n","Subclass Accuracy\n","Overall: 2.03 %\n","Seen: 9.56 %\n","Unseen: 0.00 %\n","'''"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}